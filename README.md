# scikit-learn-basics

1. kmeans (ex1 y ex2)  
2. GMM   
3. Logistic regression
4. Dimensionality Reduction  
5. Linear Regression  


## Supervised Learning

Is when the model is getting trained on a labelled dataset. A labelled dataset is one that has both input (input features, predictors) and output parameters (output labels)

data: training(80%), validation(20%)

Supervised learning is typically divided into two main categories: regression and classification. In regression, the algorithm learns to predict a continuous output value, such as the price of a house or the temperature of a city. In classification, the algorithm learns to predict a categorical output variable or class label, such as whether a customer is likely to purchase a product or not.

### Regression 

In regression, the target variable is a continuous value. The goal of regression is to predict the value of the target variable based on the input variables. **Linear regression, polynomial regression, and decision trees** are some of the examples of regression algorithms.

- Lasso Regression
- Ridge Regression
- XGBoots Regressor
- LGBM Regressor

Evaluation Metrics:
- Precision  
- Recall  
- F1-score  
- Confusion matrix

### Classification

In classification, the target variable is a categorical value. The goal of classification is to predict the class or category of the target variable based on the input variables. Some examples of classification algorithms include **logistic regression, decision trees, support vector machines, and neural networks**.

- Desicion Tree  
- Random Forest Classifier
- K-Nearest Neighbors
- Support vector Machine

Evaluation Metrics:
- Mean Square Error
- R2-score 
- MAPE  



## Unsupervised Learning

## Semi-supervised Learning


## Reinforcement Learning
